{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74d57069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "\n",
    "def get_topic_page(topic_url):\n",
    "    # TODO - add comments\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc\n",
    "def get_repo_info(h1_tag, star_tag):\n",
    "    # returns all the required info about a repository\n",
    "    a_tags = h1_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url =  base_url + a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url\n",
    " \n",
    "def get_topic_repos(topic_doc):\n",
    "    \n",
    "        h1_selection_class='f3 color-fg-muted text-normal lh-condensed'\n",
    "        repo_tags=topic_doc.find_all('h3',{'class':h1_selection_class})\n",
    "        star_tags=topic_doc.find_all('span',{'class': 'Counter js-social-count'})\n",
    "        topic_repos_dict={\n",
    "            'username':[],\n",
    "            'repo_name':[],\n",
    "            'stars':[],\n",
    "            'repo_url':[]\n",
    "        }\n",
    "        for i in range(len(repo_tags)):\n",
    "            repo_info=get_repo_info(repo_tags[i],star_tags[i])\n",
    "            topic_repos_dict['username'].append(repo_info[0])\n",
    "            topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "            topic_repos_dict['stars'].append(repo_info[2])\n",
    "            topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "        return pd.DataFrame(topic_repos_dict) \n",
    "def scrape_topic(topic_url, path):\n",
    "    if os.path.exists(path):\n",
    "        print(\"The file {} already exists. Skipping...\".format(path))\n",
    "        return\n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4408a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles\n",
    "def get_topic_descs(doc):\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
    "    topic_descs = []\n",
    "    for tag in topic_desc_tags:\n",
    "        topic_descs.append(tag.text.strip())\n",
    "    return topic_descs\n",
    "def get_topic_urls(doc):\n",
    "    topic_link_tags=doc.find_all('a',{'class': 'no-underline flex-1 d-flex flex-column'})\n",
    "    topic_urls=[]\n",
    "    base_url=\"https://github.com\"\n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url+tag['href'])\n",
    "    return topic_urls\n",
    "\n",
    "def scrape_topics():\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    topics_dict = {\n",
    "        'title': get_topic_titles(doc),\n",
    "        'description': get_topic_descs(doc),\n",
    "        'url': get_topic_urls(doc)\n",
    "    }\n",
    "    return pd.DataFrame(topics_dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cacdd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics')\n",
    "    topics_df = scrape_topics()\n",
    "    \n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    for index, row in topics_df.iterrows():\n",
    "        print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'], 'data/{}.csv'.format(row['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c4373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Scraping top repositories for \"3D\"\n",
      "Scraping top repositories for \"Ajax\"\n",
      "Scraping top repositories for \"Algorithm\"\n",
      "Scraping top repositories for \"Amp\"\n",
      "Scraping top repositories for \"Android\"\n",
      "Scraping top repositories for \"Angular\"\n",
      "Scraping top repositories for \"Ansible\"\n",
      "Scraping top repositories for \"API\"\n",
      "Scraping top repositories for \"Arduino\"\n",
      "Scraping top repositories for \"ASP.NET\"\n",
      "Scraping top repositories for \"Atom\"\n",
      "Scraping top repositories for \"Awesome Lists\"\n",
      "Scraping top repositories for \"Amazon Web Services\"\n",
      "Scraping top repositories for \"Azure\"\n",
      "Scraping top repositories for \"Babel\"\n",
      "Scraping top repositories for \"Bash\"\n",
      "Scraping top repositories for \"Bitcoin\"\n",
      "Scraping top repositories for \"Bootstrap\"\n",
      "Scraping top repositories for \"Bot\"\n",
      "Scraping top repositories for \"C\"\n",
      "Scraping top repositories for \"Chrome\"\n",
      "Scraping top repositories for \"Chrome extension\"\n",
      "Scraping top repositories for \"Command line interface\"\n",
      "Scraping top repositories for \"Clojure\"\n",
      "Scraping top repositories for \"Code quality\"\n",
      "Scraping top repositories for \"Code review\"\n",
      "Scraping top repositories for \"Compiler\"\n",
      "Scraping top repositories for \"Continuous integration\"\n",
      "Scraping top repositories for \"COVID-19\"\n",
      "Scraping top repositories for \"C++\"\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318750f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
